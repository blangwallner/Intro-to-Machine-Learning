{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Natural Language Processing Case Study\n",
    "\n",
    "## Sentiment Classification for Customer reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# import sklearn classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21560</th>\n",
       "      <td>A hilarious Action comedy in which Damian Szif...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48917</th>\n",
       "      <td>The old axiom that bored people are boring peo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40417</th>\n",
       "      <td>First of all, I have to start this comment by ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33849</th>\n",
       "      <td>If I didn't know any better, I would have thou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45148</th>\n",
       "      <td>The Broadway musical, \"A Chorus Line\" is argua...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "21560  A hilarious Action comedy in which Damian Szif...  positive\n",
       "48917  The old axiom that bored people are boring peo...  negative\n",
       "40417  First of all, I have to start this comment by ...  positive\n",
       "33849  If I didn't know any better, I would have thou...  negative\n",
       "45148  The Broadway musical, \"A Chorus Line\" is argua...  negative"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review =\n",
      "A hilarious Action comedy in which Damian Szifron takes into the lives of Díaz, a cop whose wife has cheated on him. He is living in a hotel feeling guilty about his wife's unfaithfulness, falling into depression he stops caring, running red lights just for fun, feeling sorry for himself. And Silberman, a Jewish shrink on probation, a leftist liberal who does not trust cops at all. He is told to accompany Díaz in his daily duties, unable to refuse due to the terms of his probation. Soon the situation reverts when Silberman himself finds out his wife is cheating on him, and ends up being comforted by the very person he was supposed to help, a person he did not trust at all in the beginning. A nuclear conspiracy, car thieves, international spies, a hysterical wife. Weird characters in a delightful comedy about friendship and heroism.\n",
      "\n",
      "Sentiment = positive\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print('Review =\\n{}\\n'.format(data.iloc[i,0]))\n",
    "print(\"Sentiment = {}\".format(data.iloc[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Analyze Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "### <span style=\"color:blue\">**TODO: Experiment with both Vectorizer choices and different parameters!**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stopwords\n",
    "stopwords = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "# initialize and fit vectorizer\n",
    "vect = CountVectorizer(max_features=3000, stop_words=stopwords, token_pattern=r'\\b[^\\d\\W]+\\b')\\\n",
    "                      .fit(data['review'])\n",
    "#vect = TfidfVectorizer(max_features=3000, stop_words=stopwords.words('english'), token_pattern=r'\\b[^\\d\\W]+\\b')\\\n",
    "#                      .fit(data['review'])\n",
    "\n",
    "# apply vectorizer to data set\n",
    "X = vect.transform(data['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of discarded tokens: since we chose to use only the most frequent tokens, the number of stop words goes up a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73158\n"
     ]
    }
   ],
   "source": [
    "print(len(vect.stop_words_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic information on tokens and size of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 2000\n",
      "\n",
      "First 100 features:\n",
      "['ability', 'able', 'absolute', 'absolutely', 'absurd', 'academy', 'accent', 'accept', 'accident', 'according', 'accurate', 'act', 'acted', 'acting', 'action', 'actions', 'actor', 'actors', 'actress', 'actresses', 'acts', 'actual', 'actually', 'adam', 'adaptation', 'add', 'added', 'addition', 'adds', 'admit', 'adult', 'adults', 'adventure', 'advice', 'affair', 'afraid', 'african', 'age', 'aged', 'agent', 'ages', 'ago', 'agree', 'ahead', 'air', 'al', 'alan', 'albert', 'alien', 'aliens', 'alive', 'allen', 'allow', 'allowed', 'allows', 'amateurish', 'amazing', 'america', 'american', 'americans', 'amusing', 'ancient', 'anderson', 'andy', 'angles', 'angry', 'animal', 'animals', 'animated', 'animation', 'ann', 'anna', 'anne', 'annoying', 'answer', 'anthony', 'anti', 'anybody', 'anymore', 'apart', 'apartment', 'apparent', 'apparently', 'appeal', 'appealing', 'appear', 'appearance', 'appeared', 'appears', 'appreciate', 'approach', 'appropriate', 'area', 'aren', 'army', 'art', 'arthur', 'artist', 'artistic', 'arts']\n",
      "\n",
      "Features 110 to 130:\n",
      "['atmosphere', 'attack', 'attempt', 'attempts', 'attention', 'attitude', 'attractive', 'audience', 'audiences', 'australian', 'author', 'available', 'average', 'avoid', 'award', 'aware', 'away', 'awesome', 'awful', 'awkward']\n",
      "\n",
      "Every 100th feature:\n",
      "['ability', 'asian', 'break', 'classics', 'current', 'dramatic', 'eye', 'forget', 'happened', 'industry', 'laughable', 'martin', 'needed', 'physical', 'race', 'said', 'site', 'style', 'torture', 'visuals']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Number of features: {}\\n\".format(len(feature_names)))\n",
    "print(\"First 100 features:\\n{}\\n\".format(feature_names[:100]))\n",
    "print(\"Features 110 to 130:\\n{}\\n\".format(feature_names[110:130]))\n",
    "print(\"Every 100th feature:\\n{}\\n\".format(feature_names[::100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choose classifier method and fit on data\n",
    "_______________\n",
    "### <span style=\"color:blue\">**TODO: Experiment with different classifier choices and different parameters!**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=15, min_samples_leaf=10)\n",
    "#clf = LogisticRegression(max_iter=5000)\n",
    "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "#clf = GaussianNB()\n",
    "#clf = MLPClassifier(alpha=.01, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = clf.fit(X_train, y_train)\n",
    "clf = clf.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use trained model to predict labels for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test.toarray())\n",
    "y_train_pred = clf.predict(X_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set = 77.6%\n",
      "accuracy on test set\t = 73.4%\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on training set = {:1.1f}%\".format(100*train_accuracy))\n",
    "print(\"accuracy on test set\\t = {:1.1f}%\".format(100*test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: Look at tokens associated with positive or negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print classifier does not have coeff attribute\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    indices = np.argsort(clf.coef_[0])\n",
    "    feature_names = np.array(vect.get_feature_names())[indices]\n",
    "    neg_unigrams = feature_names[:100]\n",
    "    print('Words associated with negative reviews:')\n",
    "    print(neg_unigrams)\n",
    "    pos_unigrams = feature_names[-100:-1]\n",
    "    print('\\n')\n",
    "    print('Words associated with positive reviews:')\n",
    "    print(pos_unigrams)\n",
    "except:\n",
    "    print('Print classifier does not have coeff attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply sentiment classification to new sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = lambda x: 'positive' if x == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">**TODO: Write your own review and check the detected sentiment!**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_review = ['this movie was shit and crap at the same time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of review: positive\n"
     ]
    }
   ],
   "source": [
    "# vectorize new review\n",
    "x_rev = vect.transform(my_review)\n",
    "# Classify new review\n",
    "y_pred = clf.predict(x_rev.toarray())\n",
    "print('Sentiment of review: {}'.format(sentiment(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('nlp_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vect, open('nlp_vect.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm_ml",
   "language": "python",
   "name": "pm_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
