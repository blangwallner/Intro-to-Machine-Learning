{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Natural Language Processing Case Study\n",
    "\n",
    "## Sentiment Classification for Customer reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# import sklearn classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/eh_reviews_sentiment.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3888</th>\n",
       "      <td>soda stream crystal 2.0 titan promopack soda s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>Preis/Leistungsverhältnis sehr gut Preis/Leist...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8361</th>\n",
       "      <td>Alles super gelaufen! Danke. Alles super gelau...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>Sehr gutes Gerät Sehr gutes Gerät Sehr gutes G...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6844</th>\n",
       "      <td>Funktionales Handy im unteren Preissegment Fun...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review sentiment\n",
       "3888  soda stream crystal 2.0 titan promopack soda s...  positive\n",
       "6338  Preis/Leistungsverhältnis sehr gut Preis/Leist...  positive\n",
       "8361  Alles super gelaufen! Danke. Alles super gelau...  positive\n",
       "2487  Sehr gutes Gerät Sehr gutes Gerät Sehr gutes G...  positive\n",
       "6844  Funktionales Handy im unteren Preissegment Fun...  positive"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review =\n",
      "Funktionales Handy im unteren Preissegment Funktionales Handy im unteren Preissegment Funktionales Handy im unteren Preissegment Funktionales Handy im unteren Preissegment\n",
      "\n",
      "Sentiment = positive\n"
     ]
    }
   ],
   "source": [
    "i = 4\n",
    "print('Review =\\n{}\\n'.format(data.iloc[i,0]))\n",
    "print(\"Sentiment = {}\".format(data.iloc[i,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Analyze Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "\n",
    "### <span style=\"color:blue\">**TODO: Experiment with both Vectorizer choices and different parameters!**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stopwords\n",
    "stopwords = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "# initialize and fit vectorizer\n",
    "vect = CountVectorizer(max_features=3000, stop_words=stopwords, token_pattern=r'\\b[^\\d\\W]+\\b')\\\n",
    "                      .fit(data['review'])\n",
    "#vect = TfidfVectorizer(max_features=3000, stop_words=stopwords.words('english'), token_pattern=r'\\b[^\\d\\W]+\\b')\\\n",
    "#                      .fit(data['review'])\n",
    "\n",
    "# apply vectorizer to data set\n",
    "X = vect.transform(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of discarded tokens: since we chose to use only the most frequent tokens, the number of stop words goes up a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15929\n"
     ]
    }
   ],
   "source": [
    "print(len(vect.stop_words_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['sentiment'].apply(lambda x: 1 if x == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic information on tokens and size of dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3000\n",
      "\n",
      "First 100 features:\n",
      "['_', '_top', 'ab', 'abbildung', 'abdeckung', 'abend', 'aber', 'abgeben', 'abgebildet', 'abgebrochen', 'abgelaufen', 'abgesehen', 'abgespielt', 'ablauf', 'ablesbar', 'ablesen', 'abnehmbar', 'abraten', 'abschalten', 'absolut', 'absolute', 'absoluter', 'absolutes', 'abspielen', 'abstand', 'abwicklung', 'abziehen', 'abzug', 'accu', 'acer', 'ach', 'achtung', 'activity', 'ad', 'adapter', 'ade', 'aeg', 'ahnung', 'aid', 'akku', 'akkulaufzeit', 'akkuleistung', 'akkus', 'akkusauger', 'aktion', 'aktiv', 'aktivieren', 'aktivitäten', 'aktuelle', 'aktuellen', 'aktueller', 'akzeptabel', 'alle', 'allein', 'alleine', 'allem', 'allen', 'aller', 'allerdings', 'alles', 'allgemein', 'allrounder', 'alltag', 'als', 'alt', 'alte', 'alten', 'alter', 'alternative', 'alternativen', 'altes', 'alu', 'aluminium', 'amazon', 'analog', 'anbieter', 'anbietern', 'andere', 'anderem', 'anderen', 'anderer', 'anderes', 'anders', 'android', 'anfang', 'anfangs', 'anforderungen', 'anfänger', 'angaben', 'angeblich', 'angebot', 'angeboten', 'angebracht', 'angegeben', 'angeht', 'angekommen', 'angekündigt', 'angeliefert', 'angemessen', 'angenehm']\n",
      "\n",
      "Features 110 to 130:\n",
      "['anleitung', 'anlieferung', 'anruf', 'anrufbeantworter', 'ans', 'anschaffung', 'anscheinend', 'anschliessen', 'anschließen', 'anschluss', 'anschluß', 'ansonsten', 'ansprechend', 'ansprechendes', 'anspruch', 'ansprüche', 'anstatt', 'antenne', 'antwort', 'antworten']\n",
      "\n",
      "Every 100th feature:\n",
      "['_', 'angenehmer', 'aussage', 'besitzer', 'bt', 'der', 'eher', 'entscheiden', 'farbe', 'funktionalität', 'generation', 'gleichem', 'hauptsächlich', 'hört', 'karaffen', 'ks', 'lenovo', 'md', 'mußte', 'nächste', 'positiven', 'reinigen', 'schluss', 'sinn', 'starken', 'telefon', 'unbrauchbar', 'verzichten', 'weil', 'zahnbürste']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "\n",
    "print(\"Number of features: {}\\n\".format(len(feature_names)))\n",
    "print(\"First 100 features:\\n{}\\n\".format(feature_names[:100]))\n",
    "print(\"Features 110 to 130:\\n{}\\n\".format(feature_names[110:130]))\n",
    "print(\"Every 100th feature:\\n{}\\n\".format(feature_names[::100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choose classifier method and fit on data\n",
    "_______________\n",
    "### <span style=\"color:blue\">**TODO: Experiment with different classifier choices and different parameters!**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = DecisionTreeClassifier(max_depth=15, min_samples_leaf=10)\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "#clf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "#clf = GaussianNB()\n",
    "#clf = MLPClassifier(alpha=.01, max_iter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = clf.fit(X_train, y_train)\n",
    "clf = clf.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use trained model to predict labels for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test.toarray())\n",
    "y_train_pred = clf.predict(X_train.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set = 99.4%\n",
      "accuracy on test set\t = 94.1%\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on training set = {:1.1f}%\".format(100*train_accuracy))\n",
    "print(\"accuracy on test set\\t = {:1.1f}%\".format(100*test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: Look at tokens associated with positive or negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words associated with negative reviews:\n",
      "['zurück' 'schlechte' 'enttäuscht' 'unzufrieden' 'enttäuschend' 'undicht'\n",
      " 'schafft' 'nicht' 'unittest' 'leider' 'schlecht' 'test' 'unbrauchbar'\n",
      " 'fehler' 'schlechter' 'defekt' 'null' 'enttäuschung' 'horrible' 'lieber'\n",
      " 'streamer' 'läuft' 'billige' 'software' 'zurückschicken' 'irreführende'\n",
      " 'egal' 'bereits' 'weg' 'klang' 'nie' 'absoluter' 'verliert' 'plastikmüll'\n",
      " 'überhaupt' 'müll' 'probleme' 'schade' 'ab' 'phone' 'laptop' 'wenig'\n",
      " 'total' 'finger' 'wochen' 'tv' 'werde' 'obwohl' 'hardware' 'dennoch'\n",
      " 'wenn' 'mobile' 'ca' 'voll' 'beschädigt' 'kaputt' 'falsche' 'mangelhaft'\n",
      " 'aussehen' 'poliermaschine' 'schere' 'daneben' 'schrott' 'katastrophe'\n",
      " 'nix' 'zeitschaltuhr' 'topfset' 'totaler' 'update' 'selbst' 'stunden'\n",
      " 'ungenügend' 'keine' 'dringend' 'big' 'fragen' 'ärgerlich' 'leer'\n",
      " 'geöffnet' 'munddusche' 'beim' 'touchpad' 'laut' 'schwer' 'severin'\n",
      " 'anwendung' 'low' 'fuer' 'folie' 'support' 'fast' 'gehäuse' 'abgelaufen'\n",
      " 'tassimo' 'trotz' 'hängen' 'wenigstens' 'nichts' 'la' 'nach']\n",
      "\n",
      "\n",
      "Words associated with positive reviews:\n",
      "['netzteil' 'aktiv' 'leichter' 'seine' 'kärcher' 'bedürfnisse'\n",
      " 'verspricht' 'bin' 'schick' 'monitor' 'genial' 'glas' 'sony' 'nutzen'\n",
      " 'schön' 'ipad' 'handhabung' 'ohne' 'kompatibel' 'endlich' 'duft'\n",
      " 'unseren' 'wirklich' 'gefrierschrank' 'lauter' 'im' 'genau' 'titan'\n",
      " 'makita' 'stört' 'wir' 'rot' 'anderer' 'wären' 'preiswert' 'schönes'\n",
      " 'sodastream' 'abwicklung' 'gibt' 'schöne' 'er' 'drin' 'galaxy' 'trotzdem'\n",
      " 'lange' 'asus' 'toll' 'größe' 'neu' 'erkennen' 'alles' 'beschrieben'\n",
      " 'mega' 'beste' 'schneller' 'sprudel' 'version' 'ganz' 'einsatz' 'klasse'\n",
      " 'bedienung' 'apple' 'stabilen' 'schnell' 'leicht' 'vorgängermodell'\n",
      " 'gewicht' 'jederzeit' 'einfache' 'glasflaschen' 'klein' 'schöner'\n",
      " 'toller' 'gutes' 'wert' 'kurz' 'einmal' 'tolle' 'watt' 'beurer' 'guter'\n",
      " 'große' 'leistungsverhältnis' 'anzeige' 'gewohnt' 'bedienen' 'preis'\n",
      " 'abzug' 'konnte' 'zufrieden' 'perfekt' 'begeistert' 'dabei' 'bestens'\n",
      " 'überzeugt' 'super' 'schleppen' 'schnelle' 'gute']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    indices = np.argsort(clf.coef_[0])\n",
    "    feature_names = np.array(vect.get_feature_names())[indices]\n",
    "    neg_unigrams = feature_names[:100]\n",
    "    print('Words associated with negative reviews:')\n",
    "    print(neg_unigrams)\n",
    "    pos_unigrams = feature_names[-100:-1]\n",
    "    print('\\n')\n",
    "    print('Words associated with positive reviews:')\n",
    "    print(pos_unigrams)\n",
    "except:\n",
    "    print('Print classifier does not have coeff attribute')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply sentiment classification to new sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = lambda x: 'positive' if x == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">**TODO: Write your own review and check the detected sentiment!**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_review = ['der wassersprudler ist schlecht']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of review: positive\n"
     ]
    }
   ],
   "source": [
    "# vectorize new review\n",
    "x_rev = vect.transform(my_review)\n",
    "# Classify new review\n",
    "y_pred = clf.predict(x_rev.toarray())\n",
    "print('Sentiment of review: {}'.format(sentiment(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open('nlp_model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vect, open('nlp_vect.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm_ml",
   "language": "python",
   "name": "pm_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
